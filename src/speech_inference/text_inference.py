
import streamlit as st
from src import global_configs as cf
from tools.models import facebook_bart


@st.cache_data(ttl=cf.STREAMLIT_CONFIG["Streamlit_Application_Configurations"]["Object_TTL"])
def bart_inference(text: str, model_ident: str) -> str:
    """
    Performs text summarization using the BART (Bidirectional and Auto-Regressive Transformer)
    model. The function fetches the model configuration and initializes the BART model with
    proper settings. The input text is processed to generate a summary using the specified
    model.

    Args:
        text (str): The input text to be summarized.
        model_ident (str): Identifier for the BART model configuration to be used.

    Returns:
        str: The summarized text generated by the BART model.
    """

    # Get BART model configurations
    model_configs = cf.MODELS_CONFIG[model_ident]

    # Create an instance of BART model
    model = facebook_bart.FacebookBart(
        model_name=model_configs["Model_Name"],
        device=cf.DEVICE,
        task=model_configs["Model_Task"],
        token_required=model_configs["Hugging_Face_Token"],
        token=None
    )
    summary_output = model.inference(
        input_text=text,
        min_length=model_configs["Minimum_Length"],
        max_length=model_configs["Maximum_Length"]
    )

    return summary_output
